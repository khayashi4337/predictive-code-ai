
# 分散的相対判定ネットワーク（Adaptive Relative Judgement Network）

脳の**基本構造**と**適応的差分検出理論**を統合した、実装可能な知能モデル。
各レイヤは「絶対正解」ではなく **期待パターン vs 実際パターン** の **相対差分** だけを見て自己組織化学習する。中央判定者は存在しない。

---

## TL;DR

* **主張**：脳は「情報倉庫」ではなく、**分散自律レイヤ**が**相対整合性**を判定し続けるネットワーク。
* **解法**：上位レイヤが**期待パターン**を下位へ送り、下位は**実際パターン**を上位へ返す。**層間相対判定リンク**で**差分量**を計算→**学習率**と**更新対象**を決めて上位レイヤを更新。
* **利点**：教師ラベル不要・**勾配前の差分チェック**で計算集中・エネルギー効率向上・生物学的整合（海馬/皮質/前頭前野）。

---

## 何が新しいか（ブレークスルー）

1. **教師あり/なしの越境**：外部ラベルを使わず、**期待パターン vs 実際パターン**のみで学習。
2. **判定者問題の解消**：中央の正誤判定者を置かず、**各層の独立判定**の整合で全体が決まる。
3. **計算効率**：**差分量が小さい領域はスキップ/微調整**、大きい領域のみ集中的に計算（O(重要部分のみ)）。

---

## コア概念（実装対応）

* **自律層**（感覚/パターン/概念/行動 など）

  * `期待パターン生成(宛先ID, 文脈)` / `実際パターン観測()` / `予測モデル更新(学習信号)`
* **層間相対判定リンク**（上位↔下位の**関係**が主体）

  * `相対差分計算(期待, 実際) → 相対差分`
  * `学習率調整(相対差分, 文脈) → 学習率`
  * `更新範囲決定(相対差分, 文脈) → 更新対象`
  * `計算スキップ判定(相対差分) → スキップ区分`
* **相対差分 / 差分量**

  * `差分量 = 距離(期待パターン, 実際パターン)`（距離は L2/コサイン/KL/EMD など差替可）
* **学習信号**

  * `{ 学習率, 参照差分, 更新対象 }`
* **ポリシー群**

  * 学習率ポリシー / 更新範囲ポリシー / スキップポリシー / 差分距離メトリクス

> 原則：**差分は1種類**（「期待 vs 実際」）。**相対判定は“レイヤ間の関係”の責務**。

---

## 判定者問題の解決（要点）

従来の「誰が正誤を判定するのか？」という無限後退は、
**「絶対正解の照合」→「期待パターン vs 実際パターン の相対整合」**へ問題設定を変換することで消える。
各層が局所的に**差分量**を出し、**分散的整合**で全体が収束する。

---

## 数式と疑似コード（日本語変数版）

### 1) 差分の定義

```
差分量 = 距離( 期待パターン, 実際パターン )
```

※ 距離は L2 / コサイン / KL / EMD などを選択

### 2) 学習率の決定（クリップ付き）

```
学習率 = クリップ(
  比例係数 × (差分量 ^ 曲げ指数),
  学習率_下限,
  学習率_上限
)
```

### 3) スキップ/部分更新/集中計算の判定

```
もし 差分量 < 閾値_低            → 計算を完全スキップ
もし 閾値_低 ≤ 差分量 < 閾値_高 → 部分更新（更新対象を絞る）
もし 差分量 ≥ 閾値_高           → 集中計算（優先度高で即時処理）
```

### 4) 更新対象の抽出（例：Top-K）

```
更新対象 = 重要度上位K( 期待パターン, 実際パターン, 差分寄与度 )
```

### 5) 擬似コード

```pseudo
for 各フレーム:
  for 各 層間相対判定リンク (上位層U, 下位層D):
    期待パターン = U.期待パターン生成(宛先=D, 文脈)
    実際パターン = D.実際パターン観測()
    差分量 = 距離(期待パターン, 実際パターン)

    もし 差分量 < 閾値_低:
      continue  // 完全スキップ

    学習率 = クリップ( 比例係数 * (差分量 ^ 曲げ指数),
                       学習率_下限, 学習率_上限 )
    更新対象 = 重要度上位K(期待パターン, 実際パターン, 差分寄与度)

    U.予測モデル更新({
      学習率: 学習率,
      参照差分: 差分量,
      更新対象: 更新対象
    })

    もし 差分量 ≥ 閾値_高:
      即時イベントへ投入  // 集中計算
    それ以外:
      通常フレームで処理  // 部分更新
```

---

## C4風アーキテクチャ（ビュー切替）

* **Core**：自律層 / 層間相対判定リンク / 相対差分 / 学習信号 / メトリクス&ポリシー
* **Peripheral**：視床ゲート（予測フィルタリング）/ 海馬（経験相対照合・新奇性・基準分散）/ 感度調整・競合 / 実行基盤（イベント/フレーム/介入）/ 外界I/O / MCP連携

> 図は `diagrams/relative-judgement.puml`（1ファイル・ビュー切替）を参照
>
> * 既定：全体（パッケージ間の繋がり）
> * `!define VIEW_CORE`：コア強調
> * `!define VIEW_PERIPH`：周辺強調

---

## 生物学的対応（妥当性の目安）

* **海馬**：経験パターンの**相対照合**と**新奇性**（=差分量）算出。

  * 大きな差分量：長期記憶化促進
  * 中くらい：既存記憶の微調整
  * 小さい：忘却側
  * **基準の分散化**：海馬中心の判定基準が皮質各領域へ移譲（内容のコピーではなく**判定基準**が拡がる）
* **前頭前野**：行動/思考レベルの相対判定（期待結果 vs 実際結果）、ワーキングメモリ＝**進行中の相対判定の保持**。
* **皮質**：全域で**独立並列の相対判定**（感覚→パターン→概念）。

---

## 計算効率とエネルギー

* **勾配前の差分チェック**で不要計算を事前回避
* **動的計算資源配分**：

  * 高い差分量 → 高い学習率 → 集中的計算
  * 低い差分量 → 低い学習率/スキップ → 省電力
* 目標：**O(全体) → O(重要部分のみ)**

---

## 既存AIの再解釈（統一フレーム）

* **CNN**：視覚予測の階層的相対判定
* **RNN/トランスフォーマ**：時間/系列予測の相対判定
* **Attention**：**差分量の大きい部分に計算集中**する操作
* **GAN**：生成予測 vs 実際（/擬似実際）の相対判定

---

## 評価指標とベンチマーク

* **差分量分布**：ヒストグラムと時間推移（学習で低差分量が増えるか）
* **計算削減率**：スキップ/部分更新で削れた FLOPs 比率
* **適応速度**：環境変化後の収束時間（差分量の再低下までのステップ）
* **エネルギー代理**：更新対象数・即時イベント割合・メモリアクセス削減
* **ラベル不要適応**：教師なしでの性能改善曲線（Few-shot/Zero-shot的挙動）

---

## リポジトリ構成（提案）

```
.
├── README.md
├── docs/
│   ├── ClassDiagram.md
│   ├── sequenceList.md
├── src/
│   ├── core/                         # 自律層/層間リンク/VO/ポリシー
│   ├── peripheral/                   # 視床/海馬/感度/実行基盤
│   └── examples/
└── tests/
```

---

## よくある誤解（FAQ）

* **Q：教師あり/なしで分けますか？**
  \*\*A：分けません。\*\*差分は常に「期待パターン vs 実際パターン」の1種類だけ。外部ラベルは不要です。

* **Q：誰が正解を決めますか？**
  \*\*A：誰も決めません。\*\*各層が相対判定を独立に行い、その整合が全体の整合になります。

* **Q：中央のエンジンは？**
  \*\*A：存在しません。\*\*層は自律、判定は層間リンクの責務です。

---

## 用語集（最小）

* **期待パターン**：上位層が下位層に送る「こうなるはず」
* **実際パターン**：下位層が上位層に返す「実際こうだった」
* **相対差分 / 差分量**：期待と実際の距離（ずれ）
* **学習率**：重みをどれだけ動かすか（大きいほど一気に学ぶ）
* **比例係数**：学習率の基本スケール
* **曲げ指数**：差分量に対する学習率の非線形度（>1で差分量が大きい時に強くする）
* **学習率\_下限 / 学習率\_上限**：暴走防止のための下限/上限
* **閾値\_低 / 閾値\_高**：スキップ・部分更新・集中計算の境目
* **更新対象**：今回更新するパラメータの部分集合（Top-K などで絞る）

---

## 超ミニ例（数値で直感）

* 距離=L2、比例係数=0.8、曲げ指数=1.2、学習率\_下限=1e-4、学習率\_上限=0.2
* 閾値\_低=0.03、閾値\_高=0.15
* 期待パターン=\[0.9, 0.1]、実際パターン=\[0.8, 0.2]

```
差分量 ≈ sqrt( (0.1)^2 + (-0.1)^2 ) ≈ 0.141
→ 閾値_低以上かつ 閾値_高未満 → 部分更新
→ 学習率 ≈ クリップ( 0.8 × 0.141^1.2, 1e-4, 0.2 ) ≈ 0.08（例）
→ 更新対象：上位Kユニットのみ反映（全更新はしない）
```

