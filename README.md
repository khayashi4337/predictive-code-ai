# 分散的相対判定ネットワーク（Adaptive Relative Judgement Network）

脳の**基本構造**と**適応的差分検出理論**を統合した、実装可能な知能モデル。
各レイヤは「絶対正解」ではなく**期待 vs 実際**の**相対差分**だけを見て自己組織化学習する。中央判定者は存在しない。

---

# TL;DR

* **主張**：脳は「情報倉庫」ではなく、**分散自律レイヤ**が**相対整合性**を判定し続けるネットワーク。
* **解法**：各レイヤが**期待パターン**を下位へ送り、下位は**実際パターン**を上位へ返し、**層間リンク**で差分Δを計算→**学習率ポリシー**で更新量を決める。
* **利点**：教師ラベル不要・**勾配前の差分チェック**で計算集中・エネルギー効率向上・生物学的整合（海馬/皮質/前頭前野）。

---

# 何が新しいか（ブレークスルー）

1. **教師あり/なしの越境**：外部ラベルを使わず、**期待 vs 実際**の相対差分のみで学習。
2. **判定者問題の解消**：中央の正誤判定者を置かず、**各層の独立判定**の整合で全体が決まる。
3. **計算効率**：**Δが小さい領域はスキップ/微調整**、大きい領域のみ集中的に計算（O(必要部分のみ)）。

---

# コア概念（実装対応）

* **自律層**：感覚/パターン/概念/行動など。

  * `期待パターン生成()` / `実際パターン観測()` / `予測モデル更新()`
* **層間相対判定リンク**：上位↔下位の「関係」が主体。

  * `相対差分計算()` / `学習率調整()` / `更新範囲決定()` / `計算スキップ判定()`
* **相対差分 Δ**：`Δ = d(期待, 実際)` （距離メトリクスは差し替え可能：L2/コサイン/KL/EMD など）
* **学習信号**：`{ 学習率η, 参照差分Δ, 更新スコープ }`
* **ポリシー群**：`学習率ポリシー` / `更新範囲ポリシー` / `スキップポリシー` / `差分距離メトリクス`

> 設計原則：**差分は1種類**だけ（教師あり/なし型に分けない）。**相対判定は“レイヤ間の関係”の責務**。

---

# 判定者問題の解決（要点）

従来の予測符号化の「誰が正誤を判定するのか？」という無限後退を、
**「絶対正解の照合」→「期待 vs 実際の相対整合」**へと**問題設定を変換**して解消。
各層が局所的にΔを出し、**分散的整合**で全体が収束する。

---

# 基本アルゴリズム（擬似コード）

```
for each tick:
  for each 層間相対判定リンク L (上位U, 下位D):
    E = U.期待パターン生成(宛先=D, 文脈)
    A = D.実際パターン観測()  # 視床/入力正規化後を含む
    Δ = L.相対差分計算(E, A)   # 距離メトリクスで計算
    if L.計算スキップ判定(Δ) == 完全スキップ: continue

    η = L.学習率調整(Δ, 文脈)                # 例: η = g(|Δ|)
    S = L.更新範囲決定(Δ, 文脈)               # 例: 重要ユニット/重みの選別
    U.予測モデル更新({学習率: η, 参照差分: Δ, 更新対象: S})

    if |Δ| が大:
      イベントに即時投入（集中計算）
    else:
      フレーム処理で順次更新（省電力）
```

**代表ポリシー例**

* 学習率：`η = clamp(k * |Δ|^α, η_min, η_max)`
* スキップ：`|Δ| < τ_low → スキップ / τ_low ≤ |Δ| < τ_high → 部分更新 / |Δ| ≥ τ_high → 集中計算`
* 更新範囲：Top-K 勾配見込み/注意重み/感度状態でマスクリング

---

# アーキテクチャ（C4風ビュー）

* **Core**：自律層 / 層間相対判定リンク / 相対差分 / 学習信号 / メトリクス&ポリシー
* **Peripheral**：視床ゲート（予測フィルタリング）/ 海馬（経験相対照合・新奇性・基準分散）/ 感度調整・競合 / 実行基盤（イベント/フレーム/介入）/ 外界I/O / MCP連携

**図（PlantUML）**：1ファイル内でビュー切替

* 既定：全体（パッケージ間の繋がり）
* `!define VIEW_CORE`：コア強調
* `!define VIEW_PERIPH`：周辺強調

---

# 生物学的対応（妥当性の目安）

* **海馬**：経験パターンの**相対照合**と**新奇性**（|Δ|）算出。

  * 大Δ：長期記憶化促進 / 中Δ：微調整 / 小Δ：忘却側
  * **基準の分散化**：海馬中心の判定基準が皮質各領域へ移譲される（内容コピーではなく**判定基準**が拡がる）
* **前頭前野**：行動/思考レベルの相対判定（期待結果 vs 実際結果）、ワーキングメモリ＝**進行中の相対判定の保持**。
* **皮質**：全域で**独立並列の相対判定**（感覚→パターン→概念）。
* **シナプス可塑性**：

  * LTP：期待と実際が整合（Δ小）した結合の強化
  * LTD：不整合（Δ大）で弱化
  * Hebbの法則を「**予測整合の強化**」として再解釈

---

# 計算効率とエネルギー

* **勾配前の差分チェック**で不要計算を事前回避
* **動的計算資源配分**：

  * 高Δ→高η→集中的計算
  * 低Δ→低η/スキップ→省電力
* 目的：**O(全体) → O(重要部分のみ)**

---

# 既存AIの再解釈（統一フレーム）

* **CNN**：視覚予測の階層的相対判定
* **RNN/トランスフォーマ系**：時間/系列予測の相対判定
* **Attention**：**Δの大きい部分へ計算集中**という操作
* **GAN**：生成予測 vs 実際（/擬似実際）の相対判定

---

# 評価指標とベンチマークの方向性

* **差分分布**：|Δ| のヒストグラムと時間推移（学習が進むと低Δが増えるか）
* **計算削減率**：スキップ/部分更新により削れた FLOPs 比率
* **適応速度**：環境変化後の収束時間（Δの再低下までのステップ）
* **エネルギー代理指標**：更新対象数・イベント即時処理割合・メモリアクセス削減
* **ラベル不要適応**：教師なしでの性能改善曲線（Few-shot/Zero-shot的挙動）

---

# リポジトリ構成（提案）

```
.
├── README.md
├── diagrams/
│   ├── relative-judgement.puml       # マルチビュー1ファイル
│   └── exported/                      # 画像書き出し先
├── docs/
│   ├── 01_theory_overview.md         # 本READMEを分割拡張するなら
│   ├── 02_biology_alignment.md
│   ├── 03_policies_and_metrics.md
│   └── 04_benchmarks.md
├── src/
│   ├── core/                         # 自律層/層間リンク/VO/ポリシー
│   ├── peripheral/                   # 視床/海馬/感度/実行基盤
│   └── examples/
└── tests/
```

---

# よくある誤解（FAQ）

* **Q：教師あり/なしで分けますか？**
  \*\*A：分けません。\*\*差分は常に「期待 vs 実際」の1種類だけ。外部ラベルは不要です。

* **Q：誰が正解を決めますか？**
  \*\*A：誰も決めません。\*\*各層が相対判定を独立に行い、その整合が全体の整合になります。

* **Q：中央のエンジンは？**
  \*\*A：存在しません。\*\*層は自律、判定は層間リンクの責務です。

---

# 用語集（最小）

* **期待パターン**：上位層が下位に送る予測。
* **実際パターン**：下位層が上位に返す観測。
* **相対差分 Δ**：期待と実際の距離。
* **学習信号**：学習率ηと更新スコープSを含む更新指示。
* **視床ゲート**：入力の予測フィルタリング。
* **海馬**：経験相対照合・新奇性・基準分散化。
* **基準分散化**：海馬の判定基準が皮質領域へ自律的に移る。

---

# 研究・実装の次ステップ

1. **最小コア**：2層＋1リンク＋L2距離＋単純ηポリシーでΔ収束実験
2. **スキップ/部分更新**：Top-K/閾値でFLOPs削減を可視化
3. **海馬バースト**：新奇性で一時的にηを増幅、学習のブースト効果を検証
4. **実世界I/O**：簡易環境（迷路/制御）で行動レベルまで接続

