#!/usr/bin/env python3
"""
Sinæ³¢äºˆæ¸¬çµæœã®å¯è¦–åŒ–ãƒ„ãƒ¼ãƒ«
"""

import sys
import os
import csv

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’Pythonãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.append(os.path.dirname(__file__))

from src.application.use_cases.prediction_use_case import PredictionUseCase, load_trained_model


def create_simple_plot(title: str, data_dict: dict, filename: str):
    """
    matplotlibã‚’ä½¿ã‚ãšã«ASCIIã‚¢ãƒ¼ãƒˆã§ã®ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ—ãƒ­ãƒƒãƒˆ
    """
    print(f"\nğŸ“Š {title}")
    print("=" * 60)
    
    # ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
    if 'predictions' in data_dict and 'actual_values' in data_dict:
        predictions = data_dict['predictions'][:20]  # æœ€åˆã®20å€‹
        actual_values = data_dict['actual_values'][:20]
        
        print("ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ | äºˆæ¸¬å€¤   | å®Ÿéš›å€¤   | å·®åˆ†")
        print("-" * 45)
        
        total_error = 0
        count = 0
        
        for i in range(min(len(predictions), len(actual_values))):
            pred = predictions[i]
            actual = actual_values[i]
            diff = abs(pred - actual)
            total_error += diff
            count += 1
            
            print(f"{i+1:8d} | {pred:8.4f} | {actual:8.4f} | {diff:8.4f}")
        
        if count > 0:
            avg_error = total_error / count
            print("-" * 45)
            print(f"å¹³å‡çµ¶å¯¾èª¤å·®: {avg_error:.6f}")
    
    # CSVãƒ•ã‚¡ã‚¤ãƒ«ã«çµæœã‚’ä¿å­˜
    if 'predictions' in data_dict and 'actual_values' in data_dict:
        with open(filename, 'w', newline='') as csvfile:
            writer = csv.writer(csvfile)
            writer.writerow(['index', 'prediction', 'actual', 'error'])
            
            for i in range(min(len(data_dict['predictions']), len(data_dict['actual_values']))):
                pred = data_dict['predictions'][i]
                actual = data_dict['actual_values'][i]
                error = abs(pred - actual)
                writer.writerow([i+1, pred, actual, error])
        
        print(f"ğŸ“ è©³ç´°çµæœã‚’ä¿å­˜ã—ã¾ã—ãŸ: {filename}")


def visualize_training_history(history: dict):
    """å­¦ç¿’å±¥æ­´ã®ç°¡å˜ãªè¡¨ç¤º"""
    if not history or 'train_loss' not in history:
        print("å­¦ç¿’å±¥æ­´ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        return
    
    print("\nğŸ“ˆ å­¦ç¿’å±¥æ­´")
    print("=" * 40)
    print("ã‚¨ãƒãƒƒã‚¯ | è¨“ç·´æå¤± | æ¤œè¨¼æå¤±")
    print("-" * 35)
    
    epochs = history.get('epoch', [])
    train_losses = history.get('train_loss', [])
    val_losses = history.get('val_loss', [])
    
    # 10ã‚¨ãƒãƒƒã‚¯ã”ã¨ã€ã¾ãŸã¯æœ€å¾Œã®5ã‚¨ãƒãƒƒã‚¯ã‚’è¡¨ç¤º
    display_indices = []
    for i in range(0, len(epochs), max(1, len(epochs) // 10)):
        display_indices.append(i)
    
    # æœ€å¾Œã®5ã‚¨ãƒãƒƒã‚¯ã‚’è¿½åŠ 
    for i in range(max(0, len(epochs) - 5), len(epochs)):
        if i not in display_indices:
            display_indices.append(i)
    
    for i in sorted(display_indices):
        if i < len(epochs):
            epoch = epochs[i]
            train_loss = train_losses[i] if i < len(train_losses) else 0
            val_loss = val_losses[i] if i < len(val_losses) else 0
            print(f"{epoch:6d} | {train_loss:8.6f} | {val_loss:8.6f}")


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("ğŸ¨ Sinæ³¢äºˆæ¸¬çµæœå¯è¦–åŒ–ãƒ„ãƒ¼ãƒ«")
    print("=" * 50)
    
    model_path = "models/checkpoints/sin_predictor.pth"
    data_path = "data/sin_wave.csv"
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ãƒã‚§ãƒƒã‚¯
    if not os.path.exists(model_path):
        print(f"âŒ ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {model_path}")
        print("ã¾ãš main.py --mode train ã§ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã—ã¦ãã ã•ã„")
        return
    
    if not os.path.exists(data_path):
        print(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {data_path}")
        print("ã¾ãš python generate_sin_data.py ã§ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„")
        return
    
    try:
        # ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
        print("ğŸ”„ ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚“ã§ã„ã¾ã™...")
        model, config = load_trained_model(model_path)
        predictor = PredictionUseCase(model, config)
        
        # è¤‡æ•°ã®é–‹å§‹ç‚¹ã§äºˆæ¸¬ã‚’å®Ÿè¡Œ
        start_points = [50, 200, 400, 600]
        
        for start_idx in start_points:
            print(f"\nğŸ”® é–‹å§‹ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ {start_idx} ã‹ã‚‰ã®äºˆæ¸¬:")
            
            try:
                # äºˆæ¸¬å®Ÿè¡Œ
                result = predictor.predict_from_csv(
                    data_path,
                    start_index=start_idx,
                    prediction_steps=30
                )
                
                # è©•ä¾¡
                metrics = predictor.evaluate_predictions(
                    result['predictions'],
                    result['actual_values']
                )
                
                # çµæœè¡¨ç¤º
                print(f"  äºˆæ¸¬ã‚¹ãƒ†ãƒƒãƒ—æ•°: {len(result['predictions'])}")
                print(f"  MSE: {metrics['mse']:.6f}")
                print(f"  MAE: {metrics['mae']:.6f}")
                print(f"  ç›¸é–¢ä¿‚æ•°: {metrics['correlation']:.6f}")
                
                # è©³ç´°å¯è¦–åŒ–
                output_file = f"results/prediction_{start_idx}.csv"
                os.makedirs("results", exist_ok=True)
                create_simple_plot(
                    f"äºˆæ¸¬çµæœ (é–‹å§‹:{start_idx})",
                    result,
                    output_file
                )
                
            except Exception as e:
                print(f"  âŒ é–‹å§‹ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ {start_idx} ã§ã®äºˆæ¸¬ã«å¤±æ•—: {e}")
        
        print("\nâœ… å¯è¦–åŒ–å‡¦ç†å®Œäº†!")
        print("ğŸ“ çµæœãƒ•ã‚¡ã‚¤ãƒ«ã¯ results/ ãƒ•ã‚©ãƒ«ãƒ€ã«ä¿å­˜ã•ã‚Œã¾ã—ãŸ")
        
    except Exception as e:
        print(f"âŒ å¯è¦–åŒ–å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")


if __name__ == "__main__":
    main()