# シーケンス図 一覧

## 骨格（①〜⑤）
① 概念層 → パターン層（基本往復）
目的：層間リンクで Δ・η・スキップ生成 → 概念層が更新。
登場：概念層、パターン層、層間相対判定リンク、期待/実際、相対差分、学習信号。

② パターン層 → 感覚層（低位版）
目的：低位ほどメトリクス選好が変わる例（例：L2）。
登場：パターン層、感覚層、層間相対判定リンク、差分距離メトリクス。

③ 感覚器官 → 視床ゲート → 感覚層（実際入力）
目的：実世界入力が予測フィルタリング経由で感覚層に入る。
登場：感覚器官、視床ゲート、感覚層。

④ 感覚 → 皮質 → 海馬（経験統合 → 新奇性 → LRバースト）
目的：経験統合器で束ね→海馬が新奇性・学習感度↑を皮質へ返す。
登場：感覚/パターン/概念（＋必要なら行動）、経験統合器、海馬。

⑤ 海馬 → 皮質（判定基準の分散化／コンソリデーション）
目的：基準パターンを段階的に皮質へ移譲。
登場：海馬、基準パターン、各 自律層。

## 効率化（⑥〜⑩）
⑥ スキップ三値分岐（集中計算／軽更新／完全スキップ）
目的：スキップEnumによる処理経路分岐の可視化。
登場：層間相対判定リンク、スキップポリシー、学習率ポリシー、更新スコープ。

⑦ 学習率動的調整＋更新スコープ配布
目的：η=f(Δ) と “どこを更新するか” をセットで配る。
登場：層間相対判定リンク、学習率ポリシー、学習信号、更新スコープ。

⑧ 距離メトリクスの動的切替（L2/コサイン/KL/EMD）
目的：文脈に応じてメトリクスを切替 → Δの解釈が変わる。
登場：差分距離メトリクス、距離メトリクスEnum、相対差分。

⑨ 行動層 ↔ 概念層（計画予測 vs 実行結果）
目的：前頭前野相当の相対判定と更新。
登場：行動層、概念層、層間相対判定リンク。

⑩ 低差分時の省エネ（勾配前チェックで早期終了）
目的：Δ<τ で早期打切りして計算節約。
登場：層間相対判定リンク、スキップポリシー（完全スキップ）、各 自律層。

## 運用/堅牢化（⑪〜⑯）
⑪ コールドスタート（期待ほぼゼロからの立ち上げ）
目的：期待が未成熟でも往復を回し、期待分布を形成。
登場：任意の上下層、層間相対判定リンク（低確度の期待→実際）。

⑫ 同一層内の競合・選択（横結合の勝者選択）
目的：同層内で複数候補が競合し代表解を選ぶ。
登場：自律層A/B、（補助）層内競合モジュール、抑制/脱抑制。

⑬ 例外経路（巨大Δによる非常導線 → 海馬即時介入）
目的：大きな驚きで通常の軽更新を飛ばし、基準拡張を優先。
登場：上下層、層間相対判定リンク、海馬（新奇性高→フィードバック）。

⑭ マルチ下位の集約（上位1：下位N のΔ統合法）
目的：複数下位からの実際パターンを上位で統合しΔを決定。
登場：上位層、下位層1..N、複数の層間リンク、統合ルール。

⑮ 視床ゲートの動的閾値調整（トップダウンで入力選別）
目的：上位の期待で視床ゲートのスレッショルド/ゲインを調整。
登場：上位層、視床ゲート、感覚層。

⑯ メタ学習ループ（学習率ポリシー自体の更新）
目的：ηの関数形・閾値を履歴Δで自己更新。
登場：学習率ポリシー、履歴バッファ、層間相対判定リンク（間接）。


